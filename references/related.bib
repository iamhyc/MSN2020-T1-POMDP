@article{Yang2016,
abstract = {With proliferation of smart phones and an increasing number of services provisioned by clouds, it is commonplace for users to request cloud services from their mobile devices. Accessing services directly from the Internet data centers inherently incurs high latency due to long RTTs and possible congestions in WAN. To lower the latency, some researchers propose to 'cache' the services at edge clouds or smart routers in the access network which are closer to end users than the Internet cloud. Although 'caching' is a promising technique, placing the services and dispatching users' requests in a way that can minimize the users' access delay and service providers' cost has not been addressed so far. In this paper, we study the joint optimization of service placement and load dispatching in the mobile cloud systems. We show this problem is unique to both the traditional caching problem in mobile networks and the content distribution problem in CDNs. We develop a set of efficient algorithms for service providers to achieve various trade-offs among the average latency of mobile users' requests, and the cost of service providers. Our solution utilizes user's mobility pattern and services access pattern to predict the distribution of user's future requests, and then adapt the service placement and load dispatching online based on the prediction. We conduct extensive trace driven simulations. Results show our solution not only achieves much lower latency than directly accessing service from remote clouds, but also outperforms other classical benchmark algorithms in term of the latency, cost and algorithm running time.},
author = {Yang, Lei and Cao, Jiannong and Liang, Guanqing and Han, Xu},
doi = {10.1109/TC.2015.2435781},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/07110527.pdf:pdf},
issn = {00189340},
journal = {IEEE Transactions on Computers},
keywords = {Load dispatching,mobile cloud computing,service placement},
number = {5},
pages = {1440--1452},
publisher = {IEEE},
title = {{Cost Aware Service Placement and Load Dispatching in Mobile Cloud Systems}},
volume = {65},
year = {2016}
}
@article{Chen2016,
abstract = {Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases.},
author = {Chen, Xu and Jiao, Lei and Li, Wenzhong and Fu, Xiaoming},
doi = {10.1109/TNET.2015.2487344},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/07307234.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Computation offloading,Nash equilibrium,game theory,mobile-edge cloud computing},
number = {5},
pages = {2795--2808},
publisher = {IEEE},
title = {{Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing}},
volume = {24},
year = {2016}
}
@article{Rodrigues2017,
abstract = {{\textcopyright} 2016 IEEE. Due to physical limitations, mobile devices are restricted in memory, battery, processing, among other characteristics. This results in many applications that cannot be run in such devices. This problem is fixed by Edge Cloud Computing, where the users offload tasks they cannot run to cloudlet servers in the edge of the network. The main requirement of such a system is having a low Service Delay, which would correspond to a high Quality of Service. This paper presents a method for minimizing Service Delay in a scenario with two cloudlet servers. The method has a dual focus on computation and communication elements, controlling Processing Delay through virtual machine migration and improving Transmission Delay with Transmission Power Control. The foundation of the proposal is a mathematical model of the scenario, whose analysis is used on a comparison between the proposed approach and two other conventional methods; these methods have single focus and only make an effort to improve either Transmission Delay or Processing Delay, but not both. As expected, the proposal presents the lowest Service Delay in all study cases, corroborating our conclusion that a dual focus approach is the best way to tackle the Service Delay problem in Edge Cloud Computing.},
author = {Rodrigues, Tiago Gama and Suto, Katsuya and Nishiyama, Hiroki and Kato, Nei},
doi = {10.1109/TC.2016.2620469},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/07636965.pdf:pdf},
issn = {00189340},
journal = {IEEE Transactions on Computers},
keywords = {Edge cloud computing,cloudlet,resource management,service delay minimization,transmission power control,virtualization},
number = {5},
pages = {810--819},
publisher = {IEEE},
title = {{Hybrid Method for Minimizing Service Delay in Edge Cloud Computing Through VM Migration and Transmission Power Control}},
volume = {66},
year = {2017}
}
@article{Masip-Bruin2016,
abstract = {{\textcopyright} 2016 IEEE. The recent advances in cloud services technology are fueling a plethora of information technology innovation, including networking, storage, and computing. Today, various flavors have evolved of IoT, cloud computing, and so-called fog computing, a concept referring to capabilities of edge devices and users' clients to compute, store, and exchange data among each other and with the cloud. Although the rapid pace of this evolution was not easily foreseeable, today each piece of it facilitates and enables the deployment of what we commonly refer to as a smart scenario, including smart cities, smart transportation, and smart homes. As most current cloud, fog, and network services run simultaneously in each scenario, we observe that we are at the dawn of what may be the next big step in the cloud computing and networking evolution, whereby services might be executed at the network edge, both in parallel and in a coordinated fashion, as well as supported by the unstoppable technology evolution. As edge devices become richer in functionality and smarter, embedding capacities such as storage or processing, as well as new functionalities, such as decision making, data collection, forwarding, and sharing, a real need is emerging for coordinated management of fog-to-cloud (F2C) computing systems. This article introduces a layered F2C architecture, its benefits and strengths, as well as the arising open and research challenges, making the case for the real need for their coordinated management. Our architecture, the illustrative use case presented, and a comparative performance analysis, albeit conceptual, all clearly show the way forward toward a new IoT scenario with a set of existing and unforeseen services provided on highly distributed and dynamic compute, storage, and networking resources, bringing together heterogeneous and commodity edge devices, emerging fogs, as well as conventional clouds. Introduction: The Scenario},
author = {Masip-Bruin, Xavi and Mar{\'{i}}n-Tordera, Eva and Tashakor, Ghazal and Jukan, Admela and Ren, Guang Jie},
doi = {10.1109/MWC.2016.7721750},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/07721750.pdf:pdf},
issn = {15361284},
journal = {IEEE Wireless Communications},
number = {5},
pages = {120--128},
publisher = {IEEE},
title = {{Foggy clouds and cloudy fogs: A real need for coordinated management of fog-to-cloud computing systems}},
volume = {23},
year = {2016}
}
@article{Wang2017,
abstract = {Mobile edge computing is a new cloud computing paradigm which makes use of small-sized edge-clouds to provide real-time services to users. These mobile edge-clouds (MECs) are located in close proximity to users, thus enabling users to seamlessly access applications running on MECs. Due to the co-existence of the core (centralized) cloud, users, and one or multiple layers of MECs, an important problem is to decide where (on which computational entity) to place different components of an application. This problem, known as the application or workload placement problem, is notoriously hard, and therefore, heuristic algorithms without performance guarantees are generally employed in common practice, which may unknowingly suffer from poor performance as compared to the optimal solution. In this paper, we address the application placement problem and focus on developing algorithms with provable performance bounds. We model the user application as an application graph and the physical computing system as a physical graph, with resource demands/availabilities annotated on these graphs. We first consider the placement of a linear application graph and propose an algorithm for finding its optimal solution. Using this result, we then generalize the formulation and obtain online approximation algorithms with polynomial-logarithmic (poly-log) competitive ratio for tree application graph placement. We jointly consider node and link assignment, and incorporate multiple types of computational resources at nodes.},
author = {Wang, Shiqiang and Zafer, Murtaza and Leung, Kin K.},
doi = {10.1109/ACCESS.2017.2665971},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/07847322.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Cloud computing,Graph mapping,Mobile edge-cloud (MEC),Online approximation algorithm,Optimization theory},
pages = {2514--2533},
title = {{Online Placement of Multi-Component Applications in Edge Computing Environments}},
volume = {5},
year = {2017}
}
@article{Lyu2017,
abstract = {Mobile edge computing (MEC) is of particular interest to Internet of Things (IoT), where inexpensive simple devices can get complex tasks offloaded to and processed at powerful infrastructure. Scheduling is challenging due to stochastic task arrivals and wireless channels, congested air interface, and more prominently, prohibitive feedbacks from thousands of devices. In this paper, we generate asymptotically optimal schedules tolerant to out-of-date network knowledge, thereby relieving stringent requirements on feedbacks. A perturbed Lyapunov function is designed to stochastically maximize a network utility balancing throughput and fairness. A knapsack problem is solved per slot for the optimal schedule, provided up-to-date knowledge on the data and energy backlogs of all devices. The knapsack problem is relaxed to accommodate out-of-date network states. Encapsulating the optimal schedule under up-to-date network knowledge, the solution under partial out-of-date knowledge preserves asymptotic optimality, and allows devices to self-nominate for feedback. Corroborated by simulations, our approach is able to dramatically reduce feedbacks at no cost of optimality. The number of devices that need to feed back is reduced to less than 60 out of a total of 5000 IoT devices.},
author = {Lyu, Xinchen and Ni, Wei and Tian, Hui and Liu, Ren Ping and Wang, Xin and Giannakis, Georgios B. and Paulraj, Arogyaswami},
doi = {10.1109/JSAC.2017.2760186},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08063331.pdf:pdf},
issn = {07338716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Internet of Things,Lyapunov optimization,Mobile edge computing,Partial information},
number = {11},
pages = {2606--2615},
title = {{Optimal schedule of mobile edge computing for internet of things using partial information}},
volume = {35},
year = {2017}
}
@article{Du2018,
abstract = {Cooperation between the fog and the cloud in mobile cloud computing environments could offer improved offloading services to smart mobile user equipment (UE) with computation intensive tasks. In this paper, we tackle the computation offloading problem in a mixed fog/cloud system by jointly optimizing the offloading decisions and the allocation of computation resource, transmit power, and radio bandwidth while guaranteeing user fairness and maximum tolerable delay. This optimization problem is formulated to minimize the maximal weighted cost of delay and energy consumption (EC) among all UEs, which is a mixed-integer non-linear programming problem. Due to the NP-hardness of the problem, we propose a low-complexity suboptimal algorithm to solve it, where the offloading decisions are obtained via semidefinite relaxation and randomization, and the resource allocation is obtained using fractional programming theory and Lagrangian dual decomposition. Simulation results are presented to verify the convergence performance of our proposed algorithms and their achieved fairness among UEs, and the performance gains in terms of delay, EC, and the number of beneficial UEs over existing algorithms.},
author = {Du, Jianbo and Zhao, Liqiang and Feng, Jie and Chu, Xiaoli},
doi = {10.1109/TCOMM.2017.2787700},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08240666.pdf:pdf},
issn = {00906778},
journal = {IEEE Transactions on Communications},
keywords = {Computation offloading,cloud computing,fog computing,min-max fairness,resource allocation},
number = {4},
pages = {1594--1608},
publisher = {IEEE},
title = {{Computation Offloading and Resource Allocation in Mixed Fog/Cloud Computing Systems with Min-Max Fairness Guarantee}},
volume = {66},
year = {2018}
}
@article{Fan2017,
abstract = {Mobile edge computing (MEC) can augment the computation capabilities of mobile terminals (MTs) through offloading the computational tasks from the MTs to the MEC-enabled base station (MEC-BS) covering them. However, the load of MEC-BS will rise as the increase of the scale of tasks. Existing schemes try to alleviate the load of MEC-BS through refusing, postponing, or queuing the offloading requests of the MTs; thus, the users' QoS will largely deteriorate due to service interruption and prolonged waiting and execution time. In this paper, we investigate the cooperations of multiple MEC-BSs and propose a novel scheme to enhance the computation offloading service of an MEC-BS through further offloading the extra tasks to other MEC-BSs connected to it. An optimization algorithm is proposed to efficiently solve the optimization problem which maximizes the total benefits of time and energy consumptions gained by all the MTs covered by the MEC-BS. A balance factor is used to flexibly adjust the bias of optimization between minimizations of time and energy consumption. Extensive simulations are carried out in eight different scenarios, and the results demonstrate that our scheme can largely enhance the system performance, and it outperforms the reference scheme in all scenarios.},
author = {Fan, Wenhao and Liu, Yuanan and Tang, Bihua and Wu, Fan and Wang, Zhongbao},
doi = {10.1109/ACCESS.2017.2787737},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08241344.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Computation offloading,mobile edge computing,optimization,resource management},
pages = {22622--22633},
title = {{Computation Offloading Based on Cooperations of Mobile Edge Computing-Enabled Base Stations}},
volume = {6},
year = {2017}
}
@article{Lyu2018,
abstract = {{\textcopyright} 1972-2012 IEEE. Task admission is critical to delay-sensitive applications in mobile edge computing, but is technically challenging due to its combinatorial mixed nature and consequently limited scalability. We propose an asymptotically optimal task admission approach which is able to guarantee task delays and achieve (1 - ∈)-approximation of the computationally prohibitive maximum energy saving at a time-complexity linearly scaling with devices. ∈ is linear to the quantization interval of energy. The key idea is to transform the mixed integer programming of task admission to an integer programming (IP) problem with the optimal substructure by pre-admitting resource-restrained devices. Another important aspect is a new quantized dynamic programming algorithm which we develop to exploit the optimal substructure and solve the IP. The quantization interval of energy is optimized to achieve an [O(∈),O(1/∈)]-tradeoff between the optimality loss and time complexity of the algorithm. Simulations show that our approach is able to dramatically enhance the scalability of task admission at a marginal cost of extra energy, as compared with the optimal branch and bound method, and can be efficiently implemented for online programming.},
author = {Lyu, Xinchen and Tian, Hui and Ni, Wei and Zhang, Yan and Zhang, Ping and Liu, Ren Ping},
doi = {10.1109/TCOMM.2018.2799937},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08274943.pdf:pdf},
issn = {00906778},
journal = {IEEE Transactions on Communications},
keywords = {Mobile edge computing,optimization methods,resource allocation,task admission},
number = {6},
pages = {2603--2616},
publisher = {IEEE},
title = {{Energy-Efficient Admission of Delay-Sensitive Tasks for Mobile Edge Computing}},
volume = {66},
year = {2018}
}
@article{Lyu2018a,
abstract = {Fog computing enables resource-limited network devices to help each other with computationally demanding tasks, but has yet to be implemented in large scales due to sophisticated control and network inhomogeneity. This paper presents a new fully distributed online optimization to asymptotically minimize the time-average cost of fog computing, where tasks are selected to be offloaded and processed independently between different links and devices by measuring their cost effectiveness at each time slot. A key contribution is that we optimize the cost- effectiveness measures which achieve the asymptotic optimality over infinite time. Another contribution is that we optimize placeholders at the devices; which create collaborative computing regions of tasks in the vicinity of the point of capture, prevent tasks being offloaded beyond, preserve the asymptotic optimality and reduce delay. This is achieved in a distributed fashion by discovering the optimal substructure of the placeholders. Simulations show that the average size of collaborative regions is only 3.2 out of total 500 servers, and the system income increases by 43{\%} as compared with existing techniques.},
author = {Lyu, Xinchen and Ren, Chenshan and Ni, Wei and Tian, Hui and Liu, Ren Ping},
doi = {10.1109/JSAC.2018.2815359},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08314676.pdf:pdf},
issn = {07338716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Fog computing,asymptotic optimality,collaborative region,large-scale inhomogeneous networks,stochastic subgradient method},
number = {3},
pages = {574--586},
publisher = {IEEE},
title = {{Distributed Optimization of Collaborative Regions in Large-Scale Inhomogeneous Fog Computing}},
volume = {36},
year = {2018}
}
@article{Chen2018,
abstract = {—With the development of recent innovative applications (e.g., augment reality, self-driving and vari-ous cognitive applications), more and more computation-intensive and data-intensive tasks are delay-sensitive. Mo-bile edge computing in ultra-dense network is expected as an effective solution for meeting the low latency demand. However, the distributed computing resource in edge cloud and energy dynamics in the battery of mobile device make it challenging to offload tasks for users. In this paper, leveraging the idea of software defined network, we investigate the task offloading problem in ultra-dense network aiming to minimize the delay while saving the battery life of user's equipment. Specifically, we formulate the task offloading problem as a mixed integer non-linear program which is NP-hard. In order to solve it, we transform this optimization problem into two sub-problems, i.e., task placement sub-problem and resource allocation sub-problem. Based on the solution of the two sub-problems, we propose an efficient offloading scheme. Simulation results prove that the proposed scheme can reduce 20{\%} of the task duration with 30{\%} energy saving, compared to random and uniform task offloading schemes.},
author = {Chen, Min and Hao, Yixue},
doi = {10.1109/JSAC.2018.2815360},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08314696.pdf:pdf},
issn = {07338716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Software defined networking,mobile edge computing,resource allocation,task offloading},
number = {3},
pages = {587--597},
publisher = {IEEE},
title = {{Task Offloading for Mobile Edge Computing in Software Defined Ultra-Dense Network}},
volume = {36},
year = {2018}
}
@article{Yu2018,
author = {Yu, Se-young and Secci, Stefano and Macedo, Daniel F and Langar, Rami and Neto, Jose Leal D. and Nogueira, Jose Marcos S.},
doi = {10.1109/tmc.2018.2815015},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08314708.pdf:pdf},
issn = {1536-1233},
journal = {IEEE Transactions on Mobile Computing},
number = {11},
pages = {2660--2674},
title = {{ULOOF: A User Level Online Offloading Framework for Mobile Edge Computing}},
volume = {17},
year = {2018}
}
@article{Zhang2018,
abstract = {We consider a heterogeneous network with mobile edge computing, where a user can offload its computation to one among multiple servers. In particular, we minimize the system-wide computation overhead by jointly optimizing the individual computation decisions, transmit power of the users, and computation resource at the servers. The crux of the problem lies in the combinatorial nature of multi-user offloading decisions, the complexity of the optimization objective, and the existence of inter-cell interference. Then, we decompose the underlying problem into two subproblems: i) the offloading decision, which includes two phases of user association and subchannel assignment, and ii) joint resource allocation, which can be further decomposed into the problems of transmit power and computation resource allocation. To enable distributed computation offloading, we sequentially apply a many-to-one matching game for user association and a one-to-one matching game for subchannel assignment. Moreover, the transmit power of offloading users is found using a bisection method with approximate inter-cell interference, and the computation resources allocated to offloading users is achieved via the duality approach. The proposed algorithm is shown to converge and is stable. Finally, we provide simulations to validate the performance of the proposed algorithm as well as comparisons with the existing frameworks.},
author = {Zhang, Jing and Xia, Weiwei and Yan, Feng and Shen, Lianfeng},
doi = {10.1109/ACCESS.2018.2819690},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08325478.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Mobile edge computing,game theory,heterogeneous networks,offloading strategy,resource allocation},
pages = {19324--19337},
publisher = {IEEE},
title = {{Joint Computation Offloading and Resource Allocation Optimization in Heterogeneous Networks with Mobile Edge Computing}},
volume = {6},
year = {2018}
}
@article{Wang2018,
abstract = {{\textcopyright} 2013 IEEE. Mobile edge computing (MEC) provides a promising approach to significantly reduce network operational cost and improve quality of service (QoS) of mobile users by pushing computation resources to the network edges, and enables a scalable Internet of Things (IoT) architecture for time-sensitive applications (e-healthcare, real-time monitoring, and so on.). However, the mobility of mobile users and the limited coverage of edge servers can result in significant network performance degradation, dramatic drop in QoS, and even interruption of ongoing edge services; therefore, it is difficult to ensure service continuity. Service migration has great potential to address the issues, which decides when or where these services are migrated following user mobility and the changes of demand. In this paper, two conceptions similar to service migration, i.e., live migration for data centers and handover in cellular networks, are first discussed. Next, the cutting-edge research efforts on service migration in MEC are reviewed, and a devisal of taxonomy based on various research directions for efficient service migration is presented. Subsequently, a summary of three technologies for hosting services on edge servers, i.e., virtual machine, container, and agent, is provided. At last, open research challenges in service migration are identified and discussed.},
author = {Wang, Shangguang and Xu, Jinliang and Zhang, Ning and Liu, Yujiong},
doi = {10.1109/ACCESS.2018.2828102},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08340768.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Mobile edge computing,cellular handover,live migration,migration path selection,service migration},
pages = {23511--23528},
publisher = {IEEE},
title = {{A Survey on Service Migration in Mobile Edge Computing}},
volume = {6},
year = {2018}
}
@article{Josilo2019,
abstract = {IEEE Offloading computation to a mobile cloud is a promising solution to augment the computation capabilities of mobile devices. In this paper we consider selfish mobile devices in a dense wireless network, in which individual mobile devices can offload computations through multiple access points or through the base station to a mobile cloud so as to minimize their computation costs. We provide a game theoretical analysis of the problem, prove the existence of pure strategy Nash equilibria, and provide an efficient decentralized algorithm for computing an equilibrium. For the case when the cloud computing resources scale with the number of mobile devices we show that all improvement paths are finite. Furthermore, we provide an upper bound on the price of anarchy of the game, which serves as an upper bound on the approximation ratio of the proposed decentralized algorithms. We use simulations to evaluate the time complexity of computing Nash equilibria and to provide insights into the price of anarchy of the game under realistic scenarios. Our results show that the equilibrium cost may be close to optimal, and the convergence time is almost linear in the number of mobile devices.},
author = {Josilo, Sladana and Dan, Gyorgy},
doi = {10.1109/TMC.2018.2829874},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08345749.pdf:pdf},
issn = {15580660},
journal = {IEEE Transactions on Mobile Computing},
keywords = {Computation offloading,Nash equilibria,decentralized algorithms,mobile edge computing},
number = {1},
pages = {207--220},
title = {{Selfish Decentralized Computation Offloading for Mobile Cloud Computing in Dense Wireless Networks}},
volume = {18},
year = {2019}
}
@article{Chen2018a,
abstract = {With the development of recent innovative applications (e.g., augmented reality, natural language processing, and various cognitive applications), more and more computation-intensive and rich-media tasks are delay-sensitive. Edge cloud computing is expected to be an effective solution to meet the demand for low latency. By the use of content offloading and/or computation offloading, users' quality of experience is improved with shorter delay. Compared to existing edge computing solutions, this article introduces a new concept of computing task caching and gives the optimal computing task caching policy. Furthermore, joint optimization of computation, caching, and communication on the edge cloud, dubbed Edge-CoCaCo, is proposed. Then we give the solution to that optimization problem. Finally, the simulation experimental results show that compared to the other schemes, Edge-CoCaCo has shorter delay.},
author = {Chen, Min and Hao, Yixue and Hu, Long and Hossain, M. Shamim and Ghoneim, Ahmed},
doi = {10.1109/MWC.2018.1700308},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08403947.pdf:pdf},
issn = {15361284},
journal = {IEEE Wireless Communications},
number = {3},
pages = {21--27},
publisher = {IEEE},
title = {{Edge-CoCaCo: Toward Joint Optimization of Computation, Caching, and Communication on Edge Cloud}},
volume = {25},
year = {2018}
}
@article{Naha2018,
abstract = {Emerging technologies like the Internet of Things (IoT) require latency-aware computation for real-time application processing. In IoT environments, connected things generate a huge amount of data, which are generally referred to as big data. Data generated from IoT devices are generally processed in a cloud infrastructure because of the on-demand services and scalability features of the cloud computing paradigm. However, processing IoT application requests on the cloud exclusively is not an efficient solution for some IoT applications, especially time-sensitive ones. To address this issue, Fog computing, which resides in between cloud and IoT devices, was proposed. In general, in the Fog computing environment, IoT devices are connected to Fog devices. These Fog devices are located in close proximity to users and are responsible for intermediate computation and storage. Fog computing research is still in its infancy, and taxonomy-based investigation into the requirements of Fog infrastructure, platform, and applications mapped to current research is still required. This paper starts with an overview of Fog computing in which the definition of Fog computing, research trends, and the technical differences between Fog and cloud are reviewed. Then, we investigate numerous proposed Fog computing architecture and describe the components of these architectures in detail. From this, the role of each component will be defined, which will help in the deployment of Fog computing. Next, a taxonomy of Fog computing is proposed by considering the requirements of the Fog computing paradigm. We also discuss existing research works and gaps in resource allocation and scheduling, fault tolerance, simulation tools, and Fog-based microservices. Finally, by addressing the limitations of current research works, we present some open issues, which will determine the future research direction.},
author = {Naha, Ranesh Kumar and Garg, Saurabh and Georgakopoulos, Dimitrios and Jayaraman, Prem Prakash and Gao, Longxiang and Xiang, Yong and Ranjan, Rajiv},
doi = {10.1109/ACCESS.2018.2866491},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08444370.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Fog computing,Internet of Things (IoT),IoT application,fault tolerance,fog devices,microservices},
pages = {47980--48009},
publisher = {IEEE},
title = {{Fog computing: Survey of trends, architectures, requirements, and research directions}},
volume = {6},
year = {2018}
}
@article{Dinh2018,
abstract = {{\textcopyright} 1972-2012 IEEE. Mobile edge computing (MEC) is expected to provide cloud-like capacities for mobile users (MUs) at the edge of wireless networks. However, deploying MEC systems faces many challenges, one of which is to achieve an efficient distributed offloading mechanism for multiple users in time-varying wireless environments. In this paper, we study a multi-user multi-edge-node computation offloading problem. Since edge nodes' communication and computing capacities are limited which leads resource contention when many MUs offload to the same edge node at the same time, we formulate this problem as a non-cooperative exact potential game (EPG), where each MU, in each time slot, selfishly maximizes its number of processed central processor unit (CPU) cycles and reduces its energy consumption. Assuming that channel information is static and available to MUs, we show that MUs could achieve a Nash equilibrium via a best response-based offloading mechanism. Next, we extend the problem to a practical scenario, where the number of processed CPU cycles is time-varying and unknown to MUs because of the uncertain channel information. In this case, we adopt an unknown payoff game framework and prove that the EPG properties still hold. Then, we propose a model-free reinforcement learning offloading mechanism which helps MUs learn their long-term offloading strategies to maximize their long-term utilities. Numerical results illustrate that our proposed algorithm for unknown CSI outperforms other schemes, such as local processing and random assignment, and achieves up to 87.87{\%} average long-term payoffs compared to the perfect CSI case.},
author = {Dinh, Thinh Quang and La, Quang Duy and Quek, Tony Q.S. and Shin, Hyundong},
doi = {10.1109/TCOMM.2018.2866572},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08444467.pdf:pdf},
issn = {15580857},
journal = {IEEE Transactions on Communications},
keywords = {Mobile edge computing,Q-learning,computation offloading,exact potential game,strategy learning,unknown noisy payoff game},
number = {12},
pages = {6353--6367},
publisher = {IEEE},
title = {{Learning for computation offloading in mobile edge computing}},
volume = {66},
year = {2018}
}
@article{Lyu2018b,
abstract = {By performing fog computing, a device can offload delay-tolerant computationally demanding tasks to its peers for processing, and the results can be returned and aggregated. In distributed wireless networks, the challenges of fog computing include lack of central coordination, selfish behaviors of devices, and multi-hop signaling delays, which can result in outdated network knowledge and prevent effective cooperations beyond one hop. This paper presents a new approach to enable cooperations of N selfish devices over multiple hops, where selfish behaviors are discouraged by a tit-for-tat mechanism. The tit-for-tat incentive of a device is designed to be the gap between the helps (in terms of energy) the device has received and offered; and indicates how much help the device can offer at the next time slot. The tit-for-tat incentives can be evaluated at every device by having all devices broadcast how much help they offered in the past time slot, and used by all devices to schedule task offloading and processing. The approach achieves asymptotic optimality in a fully distributed fashion with a time-complexity of less than O(N 2 ). The optimality loss resulting from multi-hop signaling delays and consequently outdated tit-for-tat incentives is proved to asymptotically diminish. Simulation results show that our approach substantially reduces the time-average energy consumption of the state of the art by 50{\%} and accommodates more tasks, by engaging devices hops away under multi-hop delays.},
author = {Lyu, Xinchen and Ni, Wei and Tian, Hui and Liu, Ren Ping and Wang, Xin and Giannakis, Georgios B. and Paulraj, Arogyaswami},
doi = {10.1109/TWC.2018.2869764},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08467524.pdf:pdf},
issn = {15582248},
journal = {IEEE Transactions on Wireless Communications},
keywords = {Distributed fog computing,Lyapunov optimization,out-of-date information,selfish devices},
number = {11},
pages = {7704--7717},
publisher = {IEEE},
title = {{Distributed online optimization of fog computing for selfish devices with out-of-date information}},
volume = {17},
year = {2018}
}
@article{Guo2018,
abstract = {To tackle the contradiction between the computation intensive applications and the resource-hungry mobile user equipments (UEs), mobile edge computing (MEC) has been provisioned as a promising solution, which enables the UEs to offload the tasks to the MEC servers. Considering the characteristics of small cell networks (SCNs), integrating MEC into SCNs is natural. But in terms of the high interference, multi-access property, and limited resources of small cell base stations (SBSs), an efficient computation offloading scheme is essential. However, there still lack comprehensive studies on this problem in the densely deployed SCNs. In this paper, we study the energy-efficient computation offloading management scheme in the MEC system with SCNs. The aim of this paper is to minimize the energy consumption of all UEs via jointly optimizing computation offloading decision making, spectrum, power, and computation resource allocation. Specially, the UEs need not only to decide whether to offload but also to determine where to offload. First, we present the computation offloading model and formulate this problem as a mix integer non-linear programming problem, which is NP-hard. Taking advantages of genetic algorithm (GA) and particle swarm optimization (PSO), we design a suboptimal algorithm named as hierarchical GA and PSO-based computation algorithm to solve this problem. Finally, the convergence of this algorithm is studied by simulation, and the performance of the proposed algorithm is verified by comparing with the other baseline algorithms.},
author = {Guo, Fengxian and Zhang, Heli and Ji, Hong and Li, Xi and Leung, Victor C.M.},
doi = {10.1109/TNET.2018.2873002},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08490683.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Mobile edge computing,computation offloading management,genetic algorithm,particle swarm optimization,small cell networks},
number = {6},
pages = {2651--2664},
title = {{An efficient computation offloading management scheme in the densely deployed small cell networks with mobile edge computing}},
volume = {26},
year = {2018}
}
@article{Yang2018,
abstract = {Mobile edge computing is conceived as an appealing technology to enhance cloud computing capability of mobile devices (MDs) at the edge of the networks. Although some researchers use the technology to address the intensive tasks' high computation needs of MDs in small-cell networks (SCNs), most of them ignore considering the interests interaction between small cells and MDs. In this paper, we study a distributed computation offloading strategy for a multi-device and multi-server system based on orthogonal frequency-division multiple access in SCNs. First, to satisfy the interest requirements of different MDs and analyze the interactions among multiple small cells, we formulate a distributed overhead minimization problem, aiming at jointly optimizing energy consumption and latency of each MD. Second, to ensure the individuals of different MDs, we formulate the proposed overhead minimization problem as a strategy game. Then, we prove the strategy game is a potential game by the feat of potential game theory. Moreover, the potential game-based offloading algorithm is proposed to reach a Nash equilibrium. In addition, to guarantee the performance of the designed algorithm, we consider the lower bound of iteration times to derive the worst case performance guarantee. Finally, the simulation results corroborate that the proposed algorithm can effectively minimize the overhead of each MD compared with different other existing algorithms.},
author = {Yang, Lichao and Zhang, Heli and Li, Xi and Ji, Hong and Leung, Victor C.M.},
doi = {10.1109/TNET.2018.2876941},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08519737.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Mobile edge computing,Nash equilibrium,computation offloading,potential game,small cell networks},
number = {6},
pages = {2762--2773},
title = {{A distributed computation offloading strategy in small-cell networks integrated with mobile edge computing}},
volume = {26},
year = {2018}
}
@article{Josilo2019a,
abstract = {Fog computing is identified as a key enabler for using various emerging applications by battery powered and computationally constrained devices. In this paper, we consider devices that aim at improving their performance by choosing to offload their computational tasks to nearby devices or to a cloud server. We develop a game theoretical model of the problem, and we use variational inequality theory to compute an equilibrium task allocation in static mixed strategies. Based on the computed equilibrium strategy , we develop a decentralized algorithm for allocating the computational tasks among nearby devices and the cloud server. We use extensive simulations to provide insight into the performance of the proposed algorithm, and we compare its performance with the performance of a myopic best response algorithm that requires global knowledge of the system state. Despite the fact that the proposed algorithm relies on average system parameters only, our results show that it provides good system performance close to that of the myopic best response algorithm.},
author = {Jo{\v{s}}ilo, Sladana and D{\'{a}}n, Gy{\"{o}}rgy},
doi = {10.1109/TNET.2018.2880874},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08571179.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Computation offloading,decentralized resource management,fog computing,game theory,task placement},
number = {1},
pages = {85--97},
title = {{Decentralized Algorithm for Randomized Task Allocation in Fog Computing Systems}},
volume = {27},
year = {2019}
}
@article{ElHaber2019,
author = {{El Haber}, Elie and Nguyen, Tri Minh and Assi, Chadi},
doi = {10.1109/TCOMM.2019.2895040},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08626532.pdf:pdf},
issn = {15580857},
journal = {IEEE Transactions on Communications},
keywords = {Branch and Bound,convex optimization,cost efficiency,hierarchical edge-clouds,multi-access edge computing,second order cone programming,task offloading},
number = {5},
pages = {3407--3421},
publisher = {IEEE},
title = {{Joint Optimization of Computational Cost and Devices Energy for Task Offloading in Multi-Tier Edge-Clouds}},
volume = {67},
year = {2019}
}
@article{Alameddine2019,
abstract = {Multi-access Edge Computing (MEC) has recently emerged as a novel paradigm to facilitate access to advanced computing capabilities at the edge of the network, in close proximity to end devices, thereby enabling a rich variety of latency sensitive services demanded by various emerging industry verticals. Internet of Things (IoT) devices, being highly ubiquitous and connected, can offload their computational tasks to be processed by applications hosted on MEC servers due to their limited battery, computing, and storage capacities. Such IoT applications providing services to offloaded tasks of IoT devices are hosted on edge servers with limited computing capabilities. Given the heterogeneity in the requirements of the offloaded tasks (different computing requirements, latency, etc.), and limited MEC capabilities, we jointly decide on the task offloading (tasks to application assignment) and scheduling (order of executing them) which yields a challenging problem of combinatorial nature. Further, we jointly decide on the computing resource allocation for the hosted applications, and we refer to this problem as the Dynamic Task Offloading and Scheduling (DTOS) problem, encompassing the three subproblems mentioned before. We mathematically formulate this problem and owing to its complexity, we design a novel thoughtful decomposition based on the technique of Logic Based Benders Decomposition. This technique solves a relaxed Master, with fewer constraints, and a subproblem, whose resolution allows the generation of cuts which will, iteratively, guide the master to tighten its search space. Ultimately, both the master and the sub-problem will converge to yield the optimal solution. We show that this technique offers several order of magnitude (more than 140 times) improvement in the run time for the studied instances. One other advantage of this method is its capability of providing solutions with performance guarantees. Finally, we use this method to highlight insightful performance trends for different vertical industries as a function of multiple system parameters with focus on delay sensitive use cases.},
author = {Alameddine, Hyame Assem and Sharafeddine, Sanaa and Sebbah, Samir and Ayoubi, Sara and Assi, Chadi},
doi = {10.1109/JSAC.2019.2894306},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08630994.pdf:pdf},
issn = {15580008},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {5G,Internet of Things,Multi-Access edge computing,resource allocation,scheduling,task offloading},
number = {3},
pages = {668--682},
publisher = {IEEE},
title = {{Dynamic Task Offloading and Scheduling for Low-Latency IoT Services in Multi-Access Edge Computing}},
volume = {37},
year = {2019}
}
@article{Liu2018,
abstract = {To overcome devices' limitations in performing computation-intense applications, mobile edge computing (MEC) enables users to offload tasks to proximal MEC servers for faster task computation. However, current MEC system design is based on average-based metrics, which fails to account for the ultra-reliable low-latency requirements in mission-critical applications. To tackle this, this paper proposes a new system design, where probabilistic and statistical constraints are imposed on task queue lengths, by applying extreme value theory. The aim is to minimize users' power consumption while trading off the allocated resources for local computation and task offloading. Due to wireless channel dynamics, users are re-associated to MEC servers in order to offload tasks using higher rates or accessing proximal servers. In this regard, a user-server association policy is proposed, taking into account the channel quality as well as the servers' computation capabilities and workloads. By marrying tools from Lyapunov optimization and matching theory, a two-timescale mechanism is proposed, where a user-server association is solved in the long timescale while a dynamic task offloading and resource allocation policy is executed in the short timescale. Simulation results corroborate the effectiveness of the proposed approach by guaranteeing highly-reliable task computation and lower delay performance, compared to baselines.},
archivePrefix = {arXiv},
arxivId = {1812.08076},
author = {Liu, Chen-Feng and Bennis, Mehdi and Debbah, Merouane and Poor, H. Vincent},
doi = {10.1109/TCOMM.2019.2898573},
eprint = {1812.08076},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08638800.pdf:pdf},
journal = {IEEE Transactions on Communications},
number = {6},
pages = {4132--4150},
publisher = {IEEE},
title = {{Dynamic Task Offloading and Resource Allocation for Ultra-Reliable Low-Latency Edge Computing}},
url = {http://arxiv.org/abs/1812.08076},
volume = {67},
year = {2018}
}
@article{Zheng2019,
author = {Zheng, Xiao and Li, Mingchu and Tahir, Muhammad and Chen, Yuanfang and Alam, Muhammad},
doi = {10.1109/ACCESS.2019.2919651},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08726290.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
pages = {1--1},
publisher = {IEEE},
title = {{Stochastic Computation Offloading and Scheduling Based on Mobile Edge Computing}},
url = {https://ieeexplore.ieee.org/document/8726290/},
volume = {7},
year = {2019}
}
@article{Wang2015,
abstract = {In mobile edge computing, local edge servers can host cloud-based services, which reduces network overhead and latency but requires service migrations as users move to new locations. It is challenging to make migration decisions optimally because of the uncertainty in such a dynamic cloud environment. In this paper, we formulate the service migration problem as a Markov Decision Process (MDP). Our formulation captures general cost models and provides a mathematical framework to design optimal service migration policies. In order to overcome the complexity associated with computing the optimal policy, we approximate the underlying state space by the distance between the user and service locations. We show that the resulting MDP is exact for uniform one-dimensional user mobility while it provides a close approximation for uniform two-dimensional mobility with a constant additive error. We also propose a new algorithm and a numerical technique for computing the optimal solution which is significantly faster than traditional methods based on standard value or policy iteration. We illustrate the application of our solution in practical scenarios where many theoretical assumptions are relaxed. Our evaluations based on real-world mobility traces of San Francisco taxis show superior performance of the proposed solution compared to baseline solutions.},
archivePrefix = {arXiv},
arxivId = {1506.05261},
author = {Wang, Shiqiang and Urgaonkar, Rahul and Zafer, Murtaza and He, Ting and Chan, Kevin and Leung, Kin K.},
doi = {10.1109/TNET.2019.2916577},
eprint = {1506.05261},
file = {:E$\backslash$:/TODAY/Semi-Online/another-collection/08727722.pdf:pdf},
journal = {IEEE/ACM Transactions on Networking},
number = {3},
pages = {1272--1288},
publisher = {IEEE},
title = {{Dynamic Service Migration in Mobile Edge Computing Based on Markov Decision Process}},
url = {http://arxiv.org/abs/1506.05261},
volume = {27},
year = {2015}
}